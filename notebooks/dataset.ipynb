{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Imports and setup\n",
    "import pprint\n",
    "\n",
    "# Optional: display full dicts cleanly\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load dataset\n",
    "\n",
    "The package provides a `Dataset` class to load and manage datasets. It supports various way of creating a dataset. It is practical for working with object detection sets of images for inspection or preparation for training, validation, or even running predictions. Below is a guide to creating a dataset and the most practical methods."
   ],
   "id": "5986460cb41c5048"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üìÅ From folder",
   "id": "c1e7630c1c73c2c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load dataset from folder\n",
    "import os\n",
    "from ct_detector.data.dataset import Dataset\n",
    "from ct_detector.model import DATASETS_DIR\n",
    "\n",
    "folder_path = os.path.join(DATASETS_DIR, \"1\", \"val\", \"images\")\n",
    "\n",
    "dset = Dataset.from_folder(folder_path)\n",
    "print(f\"Dataset loaded with {dset.size} images.\")\n"
   ],
   "id": "41b762da79a79cd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üìÑ From .txt file with image paths",
   "id": "520b4184503f7387"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assume you have a train.txt file containing image paths\n",
    "import os\n",
    "from ct_detector.data.dataset import Dataset\n",
    "from ct_detector.model import DATASETS_DIR\n",
    "\n",
    "txt_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")\n",
    "dataset_txt = Dataset.from_txt(txt_path)\n",
    "print(f\"Loaded from .txt file: {dataset_txt.size} samples\")"
   ],
   "id": "6636c581a8a2ee4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üìÑ From .yaml file (YOLO format)",
   "id": "93d517c69071c826"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standard YOLO YAML with train/val/test keys\n",
    "import os\n",
    "from ct_detector.data.dataset import Dataset\n",
    "from ct_detector.model import DATASETS_DIR\n",
    "\n",
    "yaml_path = os.path.join(DATASETS_DIR, \"1.yaml\")\n",
    "dataset_yaml = Dataset.from_yaml(yaml_path)\n",
    "print(f\"Loaded from .yaml file: {dataset_yaml.size} samples\")\n",
    "print(\"Dataset splits:\", dataset_yaml.dataset_names)"
   ],
   "id": "af229e75c6cd9750",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üìÇ From list of paths",
   "id": "3f2cb556b742213a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a small list manually or from another Dataset\n",
    "from pathlib import Path\n",
    "from ct_detector.data.dataset import Dataset\n",
    "from ct_detector.model import DATASETS_DIR\n",
    "\n",
    "some_paths = list((Path(DATASETS_DIR) / '1' / 'val' / 'images').glob(\"*.jpg\"))[:10]\n",
    "dataset_paths = Dataset.from_paths(some_paths)\n",
    "print(f\"Loaded from list of paths: {dataset_paths.size} samples\")"
   ],
   "id": "65d27454d4762107",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üß¨ Merge multiple datasets",
   "id": "27df313d491bec05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge datasets\n",
    "\n",
    "merged = Dataset.from_datasets([dataset_txt, dataset_paths])\n",
    "print(f\"Merged dataset: {merged.size} samples\")"
   ],
   "id": "c298c535342e0c0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üßπ Optional: Filter out by names",
   "id": "b0fc113e02c6ac4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "blacklist_path = os.path.join(DATASETS_DIR, \"1\", \"blacklist.txt\")  # A .txt file with image filenames to exclude\n",
    "txt_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")\n",
    "filtered = Dataset.from_txt(txt_path, exclude_names_path=blacklist_path)\n",
    "print(f\"Filtered dataset: {filtered.size} samples\")"
   ],
   "id": "fc92b163b7dbb137",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inspect dataset",
   "id": "7b6828fa6d3d2e8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inspect dataset keys\n",
    "for key, value in dset.items():\n",
    "    print(f\"Key: {key}\")"
   ],
   "id": "e7c95bd65b04d4d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Basic inspection\n",
    "print(f\"Train: {dset.train_size}, Val: {dset.val_size}, Test: {dset.test_size}\")\n",
    "print(f\"With detections: {dset.with_detection}, Without detections: {dset.without_detection}\")\n"
   ],
   "id": "fe63fabd9a0a5ede",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print a sample entry\n",
    "key = next(iter(dset.keys()))\n",
    "pp.pprint(dset[key])\n"
   ],
   "id": "799cdb8e7329a831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize an image and its boxes\n",
    "dset.visualize(key, color_conversion=\"RGBA2BGR\")"
   ],
   "id": "d3d18875cf4bd9f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If the color of the image isn't right you can experiment with different color_conversion modes.\n",
    "from ct_detector.display import COLOR_CONVERSIONS\n",
    "\n",
    "print(\"Available color conversions:\")\n",
    "for name, code in COLOR_CONVERSIONS.items():\n",
    "    print(f\"{name}: {code}\")"
   ],
   "id": "de2dcf465bebba61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sanity check\n",
    "missing, corrupted = dset.sanity_check()\n",
    "print(f\"Missing labels: {len(missing)}\\nCorrupted images: {len(corrupted)}\")\n"
   ],
   "id": "778bf1bc791363b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Class distribution (example class names)\n",
    "class_names = {0: \"elephant\", 1: \"human\", 2: \"cat\", 3: \"dog\"}\n",
    "dist = dset.class_distribution(class_names)\n",
    "pp.pprint(dist)\n"
   ],
   "id": "c03abd1e52823168",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter dataset",
   "id": "2f271608c1e1ae31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter by name\n",
    "dset.filter_by(\"name\", [\"0002_jpg.rf.1e66a3c788c21cd312d09a6288c36f4d.jpg\"])\n",
    "print(f\"After filtering: {dset.size} images\")\n"
   ],
   "id": "5ead87135c8ec1e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Subset dataset",
   "id": "750ddd90915541e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Subset and random subset\n",
    "val_subset = dset.get_subset(\"val\")\n",
    "random_subset = dset.get_random_subset(10)\n",
    "print(f\"Subset sizes: Val = {val_subset.size}, Random = {random_subset.size}\")"
   ],
   "id": "6a307330e7a313c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split dataset",
   "id": "51a7c1da50a2cd46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split dataset randomly\n",
    "dset.split_dataset(0.7, 0.2, 0.1)\n",
    "print(f\"Split sizes: Train = {dset.train_size}, Val = {dset.val_size}, Test = {dset.test_size}\")\n"
   ],
   "id": "75f7b5417842c818",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate YOLO txt and yaml\n",
    "dset.generate_yolo_files(\"demo_output\", classes=class_names, abs_paths=True, write_yaml=True)\n",
    "print(\"YOLO files generated in demo_output/\")\n"
   ],
   "id": "adc1e2731c4151ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reorganize files\n",
    "dset.reorganize_files(\"reorg_output\", by=\"dataset\")\n",
    "print(\"Files copied by dataset split to reorg_output/\")\n"
   ],
   "id": "26ea332a0a4033b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Balance dataset",
   "id": "ff24f0a359298ed4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Balance dataset\n",
    "d_bal = dset.balance_by_class(target_size=5)\n",
    "print(f\"Balanced dataset size: {d_bal.size}\")\n"
   ],
   "id": "ec83452d604f16ca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
