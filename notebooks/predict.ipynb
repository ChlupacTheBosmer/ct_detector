{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "5ab02f8e386a27a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Update the settings to point to the datasets and runs directories\n",
    "from ultralytics import settings\n",
    "from ct_detector import DATASETS_DIR, ROOT_DIR\n",
    "import os\n",
    "\n",
    "settings.update({'datasets_dir': DATASETS_DIR, 'runs_dir': os.path.join(ROOT_DIR, 'runs')})"
   ],
   "id": "70bf1bbcd0825198",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Single model predictions",
   "id": "d58e26baf0f8b301"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basic example",
   "id": "f811bd98556c2e41"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import the necessary libraries and our custom predictor\n",
    "from ultralytics import YOLO\n",
    "from ct_detector.model.predict import CtPredictor\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "model_path = MODELS['eie_t_1_yolov8m']  # or your custom model: 'path/to/best.pt'\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# Prepare the predictor and set up its parameters\n",
    "analysis_pred = CtPredictor(\n",
    "    overrides={\n",
    "        \"conf\": 0.3,      # confidence threshold\n",
    "        \"save\": False,    # don't save annotated images\n",
    "        \"save_txt\": False, # no label files\n",
    "    },\n",
    "    handle_existing_labels=\"skip\",  # not used since we aren't saving\n",
    "    labels_dir=\"\",\n",
    ")\n",
    "\n",
    "# Load the model and assign the predictor\n",
    "model = YOLO(model_path)\n",
    "model.predictor = analysis_pred\n",
    "\n",
    "# Now run predictions on a folder or an image. Stream =True is used to get results as they are processed in a form of a generator that we can iterate over as shown below.\n",
    "results = model.predict(data_path, stream=True)\n",
    "\n",
    "# results_single_analysis is a generator of Results. Let's just show five\n",
    "counter = 0\n",
    "for r in results:\n",
    "    counter += 1\n",
    "    if counter < 5:\n",
    "        print(f\"Image: {r.path}, #boxes={len(r.boxes)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction with a callback example",
   "id": "9a15e6f9c5017031"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import the necessary libraries and our custom predictor\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from ct_detector.model.predict import CtPredictor\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "\n",
    "# Load a model\n",
    "model_path = MODELS['eie_t_1_yolov8m']  # or your custom model: 'path/to/best.pt'\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# We import the default callback dictionary with keys for each step of the process.\n",
    "# We also import an example callback that displays results.\n",
    "from ultralytics.utils.callbacks import default_callbacks\n",
    "from ct_detector.callbacks.base import display_results\n",
    "\n",
    "# You can specify callbacks for each stage of the prediction process\n",
    "predictor_callbacks = default_callbacks.copy()\n",
    "predictor_callbacks['on_predict_batch_end'] = [display_results]\n",
    "\n",
    "# Prepare the predictor and set up its parameters including the callbacks\n",
    "analysis_pred = CtPredictor(\n",
    "    overrides={\n",
    "        \"conf\": 0.3,      # confidence threshold\n",
    "        \"save\": False,    # don't save annotated images\n",
    "        \"save_txt\": False, # no label files\n",
    "        \"verbose\": False # no verbose output\n",
    "    },\n",
    "    _callbacks=predictor_callbacks\n",
    ")\n",
    "\n",
    "# Load the model and assign the predictor\n",
    "model = YOLO(model_path)\n",
    "model.predictor = analysis_pred\n",
    "\n",
    "# Alternatively we assign the callbacks to the predictor after loading the model\n",
    "# model.predictor.callbacks = predictor_callbacks\n",
    "\n",
    "# Now run predictions on a folder or an image. Stream =False is used to get results at once in a form of a list of Results. They are stored in memory and can be accessed via the predictor.results attribute. However, this is not recommended for large datasets.\n",
    "results = model.predict(data_path, stream=False)\n",
    "\n",
    "# results is a list of Results. Let's just show five\n",
    "for r in results:\n",
    "    print(f\"Image: {os.path.basename(r.path)}, #boxes={len(r.boxes)}\")"
   ],
   "id": "e03fc3e57c69526",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction with auto-annotation example",
   "id": "4e35722b44e3f30f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import the necessary libraries and our custom predictor\n",
    "from ultralytics import YOLO\n",
    "from ct_detector.model.predict import CtPredictor\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "model_path = MODELS['eie_t_1_yolov8m']  # or your custom model: 'path/to/best.pt'\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# Prepare the predictor and set up its parameters, this time allowing auto-annotation\n",
    "auto_annot_pred = CtPredictor(\n",
    "    overrides={\n",
    "        \"conf\": 0.25,\n",
    "        \"save\": True,           # save annotated images\n",
    "        \"save_txt\": True       # save .txt label files\n",
    "    },\n",
    "    handle_existing_labels=\"rename\",   # rename existing .txt\n",
    "    labels_dir=\"custom_labels\",        # store them in custom_labels/ folder\n",
    ")\n",
    "\n",
    "# Load the model and assign the predictor\n",
    "model = YOLO(model_path)\n",
    "model.predictor = auto_annot_pred\n",
    "\n",
    "# Now run predictions on a folder or an image\n",
    "results = model.predict(data_path, stream=False)"
   ],
   "id": "3fabc86e0751f624",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction with individual tracking example",
   "id": "d180b5b0f639adfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import the necessary libraries and our custom predictor\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from ct_detector.model.predict import CtPredictor\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "\n",
    "# Load a model\n",
    "model_path = MODELS['eie_t_1_yolov8m']  # or your custom model: 'path/to/best.pt'\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"2\", \"test\", \"images\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# We import the default callback dictionary with keys for each step of the process.\n",
    "# We also import an example callback that displays results.\n",
    "from ultralytics.utils.callbacks import default_callbacks\n",
    "from ct_detector.callbacks.track import track_results\n",
    "from ct_detector.callbacks.base import display_results\n",
    "from ct_detector.model.track import CtTracker\n",
    "\n",
    "# Define the tracker we will use for predictions. If you want to keep the tracking memory from previous prediction run (for example when running predictions by folder)\n",
    "# do not re-initiate the tracker but keep it defined from previous runs.\n",
    "tracker = CtTracker()\n",
    "track = track_results(tracker, persist=True) # persist True to keep memory between frames\n",
    "\n",
    "# You can specify callbacks for each stage of the prediction process\n",
    "predictor_callbacks = default_callbacks.copy()\n",
    "predictor_callbacks['on_predict_batch_end'] = [track, display_results]\n",
    "\n",
    "# Prepare the predictor and set up its parameters including the callbacks\n",
    "analysis_pred = CtPredictor(\n",
    "    overrides={\n",
    "        \"conf\": 0.3,      # confidence threshold\n",
    "        \"save\": False,    # don't save annotated images\n",
    "        \"save_txt\": False, # no label files\n",
    "        \"verbose\": False # no verbose output\n",
    "    },\n",
    "    _callbacks=predictor_callbacks\n",
    ")\n",
    "\n",
    "# Load the model and assign the predictor\n",
    "model = YOLO(model_path)\n",
    "model.predictor = analysis_pred\n",
    "\n",
    "# Alternatively we assign the callbacks to the predictor after loading the model\n",
    "# model.predictor.callbacks = predictor_callbacks\n",
    "\n",
    "# Now run predictions on a folder or an image. Stream =False is used to get results at once in a form of a list of Results. They are stored in memory and can be accessed via the predictor.results attribute. However, this is not recommended for large datasets.\n",
    "results = model.predict(data_path, stream=True)\n",
    "\n",
    "# results is a list of Results. Let's just show five\n",
    "for r in results:\n",
    "\n",
    "    print(f\"Image: {os.path.basename(r.path)}, #boxes={len(r.boxes)}\")\n",
    "    if r and hasattr(r, \"boxes\"):\n",
    "        if r.boxes:\n",
    "            print(f\"Tracked successfully: {r.boxes.is_track}\")\n",
    "            print(f\"Detected individual IDs: {[str(int(ind)) for ind, cls in zip(list(r.boxes.id), list(r.boxes.cls)) if all([ind > -1, int(cls) == 2 or int(cls) == 0])] if r.boxes.id is not None else 'None identified'}\")"
   ],
   "id": "74eb988e96f520c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multi-model predictions",
   "id": "978adb8ae074727a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basic example",
   "id": "8b63230a8dfe7bb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ct_detector.model.ensemble import CtEnsembler\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "import os\n",
    "\n",
    "# 1) Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# 2) Create the ensemble\n",
    "ensembler = CtEnsembler(\n",
    "    model_paths=[MODELS['eie_t_1_yolov8m'], MODELS['eie_t_1_yolov9m']], # Specify a list of models\n",
    "    predictor_overrides={\"conf\": 0.3, \"save_txt\": False, \"verbose\": False},  # e.g. no partial labels\n",
    ")\n",
    "\n",
    "# 3) Run predictions on a .txt of images\n",
    "gen = ensembler.predict(\n",
    "    source=data_path,\n",
    "    nms_iou_thres=0.5, # threshold for overlap during result merging\n",
    "    nms_conf_thres=0.3, # threshold of conf considered during result merging\n",
    "    class_agnostic=False, # whether to consider boxes of any class for merging in case of sufficient overlap or whether only consider same class\n",
    "    class_merge_map={0:0, 1:1, 2:0, 3:2}  # Merge classes 0 and 2. Specify groups of classes that are together considered for merging.\n",
    ")\n",
    "\n",
    "# 3) For each merged frame, do more logic if you want\n",
    "for idx, merged_frame in enumerate(gen):\n",
    "    # Possibly do final .txt saving, or display bounding boxes\n",
    "    # merged_frame.save_txt(f\"ensemble_labels/frame_{idx}.txt\")\n",
    "    pass"
   ],
   "id": "73cb0213c34981a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ensembled prediction with callbacks example",
   "id": "7b60c98e2e7c33ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ct_detector.model.ensemble import CtEnsembler\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "import os\n",
    "\n",
    "# Create the ensemble\n",
    "ensembler = CtEnsembler(\n",
    "    model_paths=[MODELS['eie_t_1_yolov8m'], MODELS['eie_t_1_yolov9m']], # Specify a list of models\n",
    "    predictor_overrides={\"conf\": 0.3, \"save_txt\": False, \"verbose\": False},  # e.g. no partial labels\n",
    ")\n",
    "\n",
    "# Import callbacks that print data about made predictions and display results\n",
    "from ct_detector.callbacks.database import print_prediction_data\n",
    "from ct_detector.callbacks.base import display_results\n",
    "\n",
    "# Run predictions on a .txt of images with custom callbacks\n",
    "gen = ensembler.predict(\n",
    "    source=data_path,\n",
    "    nms_iou_thres=0.5, # threshold for overlap during result merging\n",
    "    nms_conf_thres=0.3, # threshold of conf considered during result merging\n",
    "    class_agnostic=False, # whether to consider boxes of any class for merging in case of sufficient overlap or whether only consider same class\n",
    "    class_merge_map={0:0, 1:1, 2:0, 3:2},  # Merge classes 0 and 2. Specify groups of classes that are together considered for merging.\n",
    "    _callbacks=[print_prediction_data, display_results] # A list of callback to execute after a result is merged.\n",
    ")\n",
    "\n",
    "# For each merged frame, do more logic if you want\n",
    "for idx, merged_frame in enumerate(gen):\n",
    "    # Possibly do final .txt saving, or display bounding boxes\n",
    "    # merged_frame.save_txt(f\"ensemble_labels/frame_{idx}.txt\")\n",
    "    pass"
   ],
   "id": "aae76de5d8d4a715",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
