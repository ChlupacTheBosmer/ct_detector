{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "5ab02f8e386a27a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Update the settings to point to the datasets and runs directories\n",
    "from ultralytics import settings\n",
    "from ct_detector import DATASETS_DIR, ROOT_DIR\n",
    "import os\n",
    "\n",
    "settings.update({'datasets_dir': DATASETS_DIR, 'runs_dir': os.path.join(ROOT_DIR, 'runs')})"
   ],
   "id": "70bf1bbcd0825198",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Single model predictions",
   "id": "d58e26baf0f8b301"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import the necessary libraries and our custom predictor\n",
    "from ultralytics import YOLO\n",
    "from ct_detector.model.predict import CtPredictor\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "model_path = MODELS['eie_t_1_yolov8m']  # or your custom model: 'path/to/best.pt'\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# Prepare the predictor and set up its parameters\n",
    "analysis_pred = CtPredictor(\n",
    "    overrides={\n",
    "        \"conf\": 0.3,      # confidence threshold\n",
    "        \"save\": False,    # don't save annotated images\n",
    "        \"save_txt\": False, # no label files\n",
    "    },\n",
    "    handle_existing_labels=\"skip\",  # not used since we aren't saving\n",
    "    labels_dir=\"\",\n",
    ")\n",
    "\n",
    "# Load the model and assign the predictor\n",
    "model = YOLO(model_path)\n",
    "model.predictor = analysis_pred\n",
    "\n",
    "# Now run predictions on a folder or an image. Stream =True is used to get results as they are processed in a form of a generator that we can iterate over as shown below.\n",
    "results = model.predict(data_path, stream=True)\n",
    "\n",
    "# results_single_analysis is a generator of Results. Let's just show five\n",
    "counter = 0\n",
    "for r in results:\n",
    "    counter += 1\n",
    "    if counter < 5:\n",
    "        print(f\"Image: {r.path}, #boxes={len(r.boxes)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import the necessary libraries and our custom predictor\n",
    "from ultralytics import YOLO\n",
    "from ct_detector.model.predict import CtPredictor\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "model_path = MODELS['eie_t_1_yolov8m']  # or your custom model: 'path/to/best.pt'\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# We can define a callback function to be called at different stages of the prediction process. It always accepts the predictor as its argument.\n",
    "def demo_callback(predictor):\n",
    "    \"\"\"\n",
    "    Example post-inference callback that plots the results.\n",
    "    \"\"\"\n",
    "    for r in predictor.results:\n",
    "        display(Image.fromarray(r.plot()).resize((400, 400)))\n",
    "\n",
    "# You can specify callbacks for each stage of the prediction process\n",
    "from ultralytics.utils.callbacks import default_callbacks\n",
    "predictor_callbacks = default_callbacks.copy()\n",
    "predictor_callbacks['on_predict_batch_end'] = [demo_callback]\n",
    "\n",
    "# Prepare the predictor and set up its parameters including the callbacks\n",
    "analysis_pred = CtPredictor(\n",
    "    overrides={\n",
    "        \"conf\": 0.3,      # confidence threshold\n",
    "        \"save\": False,    # don't save annotated images\n",
    "        \"save_txt\": False, # no label files\n",
    "        \"verbose\": False # no verbose output\n",
    "    },\n",
    "    _callbacks=predictor_callbacks,\n",
    "    handle_existing_labels=\"skip\",  # not used since we aren't saving\n",
    "    labels_dir=\"\",\n",
    ")\n",
    "\n",
    "# Load the model and assign the predictor\n",
    "model = YOLO(model_path)\n",
    "model.predictor = analysis_pred\n",
    "\n",
    "# Alternatively we assign the callbacks to the predictor after loading the model\n",
    "# model.predictor.callbacks = predictor_callbacks\n",
    "\n",
    "# Now run predictions on a folder or an image. Stream =False is used to get results at once in a form of a list of Results. They are stored in memory and can be accessed via the predictor.results attribute. However, this is not recommended for large datasets.\n",
    "results = model.predict(data_path, stream=False)\n",
    "\n",
    "# results is a list of Results. Let's just show five\n",
    "for r in results[:5]:\n",
    "    print(f\"Image: {os.path.basename(r.path)}, #boxes={len(r.boxes)}\")"
   ],
   "id": "e03fc3e57c69526",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import the necessary libraries and our custom predictor\n",
    "from ultralytics import YOLO\n",
    "from ct_detector.model.predict import CtPredictor\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "model_path = MODELS['eie_t_1_yolov8m']  # or your custom model: 'path/to/best.pt'\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "# Prepare the predictor and set up its parameters, this time allowing auto-annotation\n",
    "auto_annot_pred = CtPredictor(\n",
    "    overrides={\n",
    "        \"conf\": 0.25,\n",
    "        \"save\": True,           # save annotated images\n",
    "        \"save_txt\": True       # save .txt label files\n",
    "    },\n",
    "    handle_existing_labels=\"rename\",   # rename existing .txt\n",
    "    labels_dir=\"custom_labels\",        # store them in custom_labels/ folder\n",
    ")\n",
    "\n",
    "# Load the model and assign the predictor\n",
    "model = YOLO(model_path)\n",
    "model.predictor = auto_annot_pred\n",
    "\n",
    "# Now run predictions on a folder or an image\n",
    "results = model.predict(data_path, stream=False)"
   ],
   "id": "3fabc86e0751f624",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multi-model predictions",
   "id": "978adb8ae074727a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ct_detector.model.ensemble import CtEnsembler\n",
    "from ct_detector.model import MODELS, DATASETS, DATASETS_DIR\n",
    "import os\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Get a dataset\n",
    "data_path = os.path.join(DATASETS_DIR, \"1\", \"val.txt\")  # or your dataset .yaml or folder of images\n",
    "\n",
    "def example_callback(merged_result, frame_idx):\n",
    "    display(Image.fromarray(merged_result.plot()).resize((400, 400)))\n",
    "\n",
    "# 1) Create the ensemble\n",
    "ensembler = CtEnsembler(\n",
    "    model_paths=[MODELS['eie_t_1_yolov8m'], MODELS['eie_t_1_yolov9m']],\n",
    "    predictor_overrides={\"conf\": 0.3, \"save_txt\": False, \"verbose\": False},  # e.g. no partial labels\n",
    ")\n",
    "\n",
    "# 2) Run predictions on a directory of images\n",
    "gen = ensembler.predict(\n",
    "    source=data_path,\n",
    "    nms_iou_thres=0.5,\n",
    "    nms_conf_thres=0.3,\n",
    "    class_agnostic=False,\n",
    "    class_merge_map={0:0, 1:1, 2:0, 3:2},  # Merge classes 0 and 2\n",
    "    frame_callback=example_callback\n",
    ")\n",
    "\n",
    "# 3) For each merged frame, do more logic if you want\n",
    "for idx, merged_frame in enumerate(gen):\n",
    "    # Possibly do final .txt saving, or display bounding boxes\n",
    "    # merged_frame.save_txt(f\"ensemble_labels/frame_{idx}.txt\")\n",
    "    pass"
   ],
   "id": "73cb0213c34981a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7851ae2d484da8d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aae76de5d8d4a715",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
